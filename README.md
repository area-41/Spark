<p align=center><img width="597" height="178" alt="image" src="https://github.com/user-attachments/assets/3790244d-d1f6-4bf4-992d-3f6f78742d35" /></p>

# [Apache Spark](https://spark.apache.org/) no [Databricks](https://www.databricks.com/br)

Este reposit√≥rio re√∫ne **conte√∫do diverso, experimentos e exemplos pr√°ticos** utilizando **Apache Spark no Databricks**, com foco em **processamento distribu√≠do de dados**, **an√°lise em larga escala** e **boas pr√°ticas de engenharia de dados**.üî•


### Objetivos do Reposit√≥rio
- Investigar o funcionamento do **Apache Spark** em ambientes distribu√≠dos  
- Explorar o uso do **Databricks** para analytics e engenharia de dados  
- Desenvolver pipelines escal√°veis e perform√°ticos  
- Aplicar boas pr√°ticas de versionamento, organiza√ß√£o e qualidade de dados  
- Criar bases para aplica√ß√µes anal√≠ticas e de machine learning  

#### Conte√∫dos Abordados
    - Introdu√ß√£o ao Apache Spark e arquitetura distribu√≠da  
    - PySpark: DataFrames, SQL e fun√ß√µes nativas  
    - Leitura e escrita de dados em diferentes formatos (JSON, Parquet, Delta)  
    - Otimiza√ß√£o de desempenho (partitions, cache, broadcast, joins)  
    - Uso de **Delta Lake** no Databricks  
    - Orquestra√ß√£o b√°sica de pipelines  
    - Integra√ß√£o com Machine Learning e Analytics  

### Tecnologias Utilizadas
- **Apache Spark**
- **Databricks**
- **PySpark**
- **Delta Lake**
- **Python**
- **SQL**

---
### üìÇ Estrutura do Reposit√≥rio

```text
spark/
‚îú‚îÄ‚îÄ notebooks/        # Notebooks Databricks e estudos pr√°ticos
‚îú‚îÄ‚îÄ datasets/         # Dados de exemplo para testes
‚îú‚îÄ‚îÄ pipelines/        # Scripts e fluxos de processamento
‚îú‚îÄ‚îÄ utils/            # Fun√ß√µes auxiliares e reutiliz√°veis
‚îî‚îÄ‚îÄ README.md         # Documenta√ß√£o do projeto
```
Material complementar: [IBM](https://www.ibm.com/br-pt/products/instana/supported-technologies/high-performance-spark-best-practices)
